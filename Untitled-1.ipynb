{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import shutil\n",
    "import time\n",
    "import xml.etree.ElementTree as et\n",
    "import splitfolders\n",
    "import wget\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected device: cpu\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "print('Connected device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загружаем датасет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перенесем в папку data наш датасет\n",
    "source_dir = \"C:/Users/илья/Desktop/MIPT/Хакатон/Project/Грибы\"\n",
    "target_dir = 'data/Грибы/'\n",
    "folder_names = os.listdir(source_dir)\n",
    "for folder_name in folder_names:\n",
    "    shutil.move(os.path.join(source_dir, folder_name), target_dir)\n",
    "\n",
    "# os.mkdir('data')\n",
    "# для загрузки с гугл диска \n",
    "# url = 'https://drive.google.com/uc?export=download&id=120xqh0mYtYZ1Qh7vr-XFzjPbSKivLJjA'\n",
    "# file_name = wget.download(url, 'data/')\n",
    "\n",
    "# with ZipFile(file_name, 'r') as zip_file:\n",
    "#     zip_file.extractall()\n",
    "\n",
    "# link_lst = [eatable, poisonous]\n",
    "# for link in link_lst:\n",
    "#     wget.download(link, 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Разделим данные на train, test, valid****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 0 files [00:00, ? files/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2639 files [01:11, 37.09 files/s] \n"
     ]
    }
   ],
   "source": [
    "# определяем путь к папке с исходными файлами\n",
    "input_folder = \"data/Грибы\" # \n",
    " \n",
    "# разбиваем датасет на папки с процентным соотношением числа файлов\n",
    "splitfolders.ratio(input_folder, 'data/Грибы/mooshrooms_splited', ratio = (0.7, 0.15, 0.15), seed=13, group_prefix=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset.\n",
    "train_dataset = ImageFolder(\n",
    "    root = \"data/Грибы/mooshrooms_splited/train\"\n",
    ")\n",
    "# Validation dataset.\n",
    "valid_dataset = ImageFolder(\n",
    "    root = 'data/Грибы/mooshrooms_splited/val'\n",
    ")\n",
    "# Test dataset\n",
    "test_dataset = ImageFolder(\n",
    "    root = 'data/Грибы/mooshrooms_splited/test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Произведем нормализацию и аугментацию - автовыравнивание изображений и автоконтраста (чтобы улучшить обобщающую способность моделей и внизить риск переобучения).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "train_dataset.transform = transforms.Compose([\n",
    "    transforms.Resize([80, 80]),\n",
    "    transforms.RandomHorizontalFlip(), # augmentations\n",
    "    transforms.RandomAutocontrast(), # augmentations\n",
    "    transforms.RandomEqualize(), # augmentations\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "valid_dataset.transform = transforms.Compose([\n",
    "    transforms.Resize([80, 80]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "test_dataset.transform = transforms.Compose([\n",
    "    transforms.Resize([80, 80]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data loaders.\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "# Validation data loaders.\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "# Test data loaders\n",
    "test_loader = DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём предобученную нейросеть GoogLeNet.\n",
    "\n",
    "Добавим один слой с выходным параметром out_feature=2 \n",
    "\n",
    "Замораживаем все слои, кроме последних двух."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google(): # pretrained=True для tensorflow\n",
    "    model = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "    model.fc = torch.nn.Linear(1024, len(train_dataset.classes))\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.inception3a.requires_grad = False\n",
    "    model.inception3b.requires_grad = False\n",
    "    model.inception4a.requires_grad = False\n",
    "    model.inception4b.requires_grad = False\n",
    "    model.inception4c.requires_grad = False\n",
    "    model.inception4d.requires_grad = False\n",
    "    model.inception4e.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Определяем функцию обучения модели.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, epoch=10):\n",
    "    loss_train, acc_train = [], []\n",
    "    loss_valid, acc_valid = [], []\n",
    "    count = 0\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        losses, equals = [], []\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Train.\n",
    "        model.train()\n",
    "        for i, (image, target) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(image)\n",
    "            loss = criterion(output,target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            equals.extend(\n",
    "                [x.item() for x in torch.argmax(output, 1) == target])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        loss_train.append(np.mean(losses))\n",
    "        acc_train.append(np.mean(equals))\n",
    "        losses, equals = [], []\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Validate.\n",
    "        model.eval()\n",
    "        for i , (image, target) in enumerate(valid_loader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output,target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            equals.extend(\n",
    "                [y.item() for y in torch.argmax(output, 1) == target])\n",
    "\n",
    "        loss_valid.append(np.mean(losses))\n",
    "        acc_valid.append(np.mean(equals))\n",
    "\n",
    "    return loss_train, acc_train, loss_valid, acc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GoogLeNet\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:47:23<00:00, 3884.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train: [0.613759479956663, 0.7264355362946913, 0.8109425785482124, 0.8499458288190682, 0.9111592632719393, 0.9295774647887324, 0.9517876489707475, 0.9609967497291441, 0.9604550379198267, 0.9777898158179849] \n",
      "acc_valid: [0.6911392405063291, 0.7291139240506329, 0.7265822784810126, 0.7468354430379747, 0.7468354430379747, 0.7443037974683544, 0.7443037974683544, 0.7443037974683544, 0.7265822784810126, 0.759493670886076]\n",
      "loss_train: [0.7829130846878578, 0.5669744549126461, 0.4466885641731065, 0.3582612206709796, 0.2557974136595068, 0.20113099944488755, 0.16277205770642594, 0.12011724559525991, 0.10785711479598079, 0.07243275690566876] \n",
      "loss_valid: [0.6753063729176154, 0.5985233531548426, 0.5991730506603534, 0.5612080234747666, 0.6065942232425396, 0.6502542644739151, 0.6412237217793098, 0.6823313396710616, 0.7287287230675037, 0.7676346531281104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "model = google() \n",
    "print('Model: GoogLeNet\\n')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_train, acc_train, loss_valid, acc_valid = train(\n",
    "model, optimizer, train_loader, valid_loader)\n",
    "print('acc_train:', acc_train, '\\nacc_valid:', acc_valid)\n",
    "print('loss_train:', loss_train, '\\nloss_valid:', loss_valid)\n",
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверяем точность модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 75 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "   for data in test_loader:\n",
    "     images, labels = data\n",
    "    #  print(images)\n",
    "    #  print(f\"Label: {labels.size(0)}\")\n",
    "     outputs = model(images)\n",
    "     _, predicted = torch.max(outputs.data, 1)\n",
    "    #  print(f\"foft max: {torch.max(outputs.data, 1)}\")\n",
    "     total += labels.size(0)\n",
    "     correct += (predicted == labels).sum().item()\n",
    "     \n",
    "print(f'Model accuracy: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Работоспособность модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eatble\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://avatars.mds.yandex.net/i?id=08ecf40616c96615f057052aa310bbb1ac90582d-4143030-images-thumbs&n=13\"\n",
    "\n",
    "# функция, приводящая изображение в нужный для модели формат\n",
    "def to_prepaate_img(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # load image in RGB mode (png files contains additional alpha channel)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    # set up transformation to resize the image\n",
    "    resize = transforms.Resize([70, 70])\n",
    "    img = resize(img)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # apply transformation and convert to Pytorch tensor\n",
    "    img_tenzor = to_tensor(img)\n",
    "    # torch.Size([3, 70, 70])\n",
    "    img_norm = normalize(img_tenzor)\n",
    "    # to_normalize = transforms.Normalize()\n",
    "\n",
    "    # add another dimension at the front to get NCHW shape\n",
    "    tensor = img_tenzor.unsqueeze(0)\n",
    "    # torch.Size([1, 3, 70, 70])\n",
    "    return tensor\n",
    "\n",
    "image = to_prepaate_img(url)\n",
    "outputs = model(image)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "classes = { \n",
    "           \"tensor(0)\": \"eatble\", \n",
    "           \"tensor(1)\": \"not eatble\"\n",
    "           }\n",
    "# print(classes[tensor[0]])\n",
    "print(classes[str(predicted[0])])\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  сохраняем модель в объект pkl\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
